# Tokenizer-Viz 

Simply , Tokenizing is the process where we take a corpus of texts and then convert them into numbers, There are many ways to optimize our codes when training Language models , Tokenizing is one of them.

For example, consider a tokenizer trained predominantly on English texts. Such a tokenizer is typically optimized to handle English text efficiently. It can tokenize English sentences into fewer tokens or numbers compared to a more generic tokenizer. This efficiency arises because the tokenizer is specifically tuned to the language’s vocabulary and structure, thereby minimizing the number of tokens required to represent the text.

To illustrate this, we compared several tokenizers by analyzing their performance on a sample text. The tokenizers evaluated are:

- `gpt-4o` from Tiktoken
- `sarvam-2b` from Hugging Face
- `gemma-2-2b` from Hugging Face
- `llama-3.1-storm` from Hugging Face
- `openhathi` from Hugging Face
# Getting started 
- If you want to try out and just for fun 

```bash
git clone  https://github.com/dame-cell/tokenzier-viz.git
```
- and then just try running the code on the notebook.ipynb :)


# Generalized Tokenizer Evaluation 

Here , we test the tokenizer on generic and longer context samples of text 
`PS: The sample text is just a subset of what we evaluated them on,the true text is just too long`

```python 
भूतविद्या क्या है? अध्यात्मवाद की बात करें तो ज्यादातर लोगयह भावना कॉल, दिवंगत रिश्तेदारों और प्रसिद्ध लोगों के साथ संचार प्रस्तुत करता है जिन्हें रहस्यमय फिल्मों में देखा गया है। इस लेख में हम यह जानने की कोशिश करेंगे कि वास्तव में आध्यात्मिकता क्या है, इसकी उत्पत्ति कहां और कब हुई, भविष्य में इसका विकास कैसे हुआ। "अध्यात्मवाद" शब्द लैटिन स्पिरिटस से बना था, जिसका अर्थ है "आत्मा, आत्मा," और इसका अर्थ है धार्मिक और दार्शनिक सिद्धांत। एक शिक्षण के रूप में आध्यात्मिकताः यह क्या है? अध्यात्मवाद की रहस्यमय शिक्षाओं का सार हो सकता हैइस धारणा के रूप में सूत्रबद्ध करें कि किसी व्यक्ति का आध्यात्मिक अंग शरीर की शारीरिक मृत्यु के बाद भी अपना अस्तित्व बनाए रखता है। इसके अलावा, यह एक नियम के रूप में, एक मध्यस्थ के माध्यम से रहने वाले के साथ संवाद करने में सक्षम है। इस सिद्धांत के अनुयायियों का दावा है कि आत्माएं प्राकृतिक घटनाओं और संपूर्ण भौतिक सार को नियंत्रित करती हैं। बुरी आत्माओं की सहायता से किए जाने वाले जादू के टोटकों को जादू टोना कहा जाता है। बाइबल और, तदनुसार, चर्च स्पष्ट रूप से आध्यात्मिकता के सभी रूपों की निंदा करता है। 

```


```python
There is so much to think about when packing for a trip to Indonesia. More so for an extended trip. Surfers might not carry as much stuff as a kiteboarder, but a surfer planning on a more extended surf trip is going to need to pack carefully. There is a golden rule when packing for a surf trip or any trip whatsoever – 'half the clothing and twice the money.'Outerknown boardshort made from 100% Australian Merino wool.Threads.You're going into boardshorts territory, so that cuts out a whole list of clothing you're not going to need. There is no need for jeans, no jackets, no tracksuits and no socks. It makes a big difference if you eliminate all of those except for maybe a pair of socks or two, especially for flying, and one or two long shirts or thin jackets for late evenings on the beach.For most of your trip, you'll be living in boardshorts and tee shirts, so you do need a couple of pairs of boardies and a pile of tees. A couple of wife-beaters 

```

We tokenized the sample text using each of these tokenizers and measured the number of tokens generated. The results are visualized in the bar chart below, which shows the number of tokens produced by each tokenizer.


| Hindi | English |
|:-----:|:-------:|
| <img src="images/plot_bar.png" width="900" alt="Tokenization Comparison Hindi"> | <img src="images/plot_english_bar.png" width="900" alt="Tokenization Comparison English"> | 

The bar chart provides a clear comparison of how efficiently each tokenizer processes the text. The tokenizer with the smallest number of tokens demonstrates the most efficient tokenization for the given sample text.

Based on the plots for both english and Hindi:
- we can see that the for general case `gpt-4o` will be more effecient 
- but for hindi `sarvam` is just soo much better which makes it more effecient for training Indic-Languages 

Now, I tried to used each tokenizer to tokenize samples of text

The plot compares token lengths generated by different tokenizers across various text samples over time. 



| Hindi | English |
|:-----:|:-------:|
| <img src="images/time_over_hindi.png" width="900" alt="Tokenization Comparison Hindi"> | <img src="images/time_over_english.png" width="900" alt="Tokenization Comparison English"> | 

# Code Testing and Validation 

The sample text was extracted from huggingface dataset `iamtarun/python_code_instructions_18k_alpaca` 

```python
def check_contains(query, word): 
  if query.find(word) != -1: 
    return True 
  return False 

result = check_contains(query, word)
```

| Multiple-samples |One sample |
|:-----:|:-------:|
| <img src="images/time_over_code.png" width="900" alt="Tokenization Comparison code"> | <img src="images/plot_code_bar.png" width="900" alt="Tokenization Comparison code"> | 

From the results, it is evident that the GPT-4O tokenizer excels in handling code-related text. In contrast, Sarvam-2B performs worse compared to the other tokenizers.

# MATH Testing and Validation
For the math-related text, we use the following function:

$$
g(z) = \sum_{n=0}^{\infty} \frac{g^{(n)}(b)}{n!} (z - b)^n
$$

| Multiple-samples |One sample |
|:-----:|:-------:|
| <img src="images/time_over_math.png" width="900" alt="Tokenization Comparison math"> | <img src="images/plot_math_bar.png" width="900" alt="Tokenization Comparison math"> | 

Similarly, for mathematical text, the GPT-4O tokenizer outperforms all the others.

# Conclusion

- when it comes to code and math the best tokenizer is GPT-4o with ,which kinda make sense because gpt-4o tokenizer maybe  was trained on huge corpus of texts 

- whereas  Sarvam-2B tokenizer performs better on Hindi text samples, which make sense since they actually train their tokenizer on different Indic-Langugaes
